{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['V1_TheInterpretedChineseSutra.pdf', 'V2_TheInterpretedChineseSutra.pdf']\n",
      "Total Number of Documents:205\n",
      "page_content='⾃菩提達摩攜四卷楞伽經東渡到中國，開啟禪宗直指⼈⼼、不⽴⽂字、教外別傳之旨，以楞伽經印證開悟因緣，期間經由⼆祖慧可禪師、三祖僧璨禪師、四祖道信禪師⾄五祖弘忍禪師，禪⾵逐漸由印度如來禪漸修知⾒轉換⾄祖師禪頓悟知⾒。尤其傳到六祖惠能，禪⾵更能根植、相應中⼟⽂化，並以⾦剛經印證開悟因緣。 楞嚴經云：「無⽣滅性為因地⼼，然後圓成果地修證。」六祖云：「菩提⾃性，本來清淨，但⽤此⼼，直了成佛。」兩者意義內涵實屬不異。由此可⾒，從佛開悟成道、祖祖相傳⾄於今⽇，以⼼印⼼，所悟所證的⼀致性、可修性、可證性。在世界宗教乃⾄佛教本身亦罕⾒如此⾼度的⼀致性。 壇經闡明⼼性意旨的內容，是吾⼈於茫茫三界輪迴中出離苦輪的⼀盞明燈。希望讀此書、⾒此書者，皆種下菩提智慧解脫因緣。讀者若能依壇經所述修⾏，定能同沾佛祖智慧與護佑，並於不久將來證得菩提涅槃果位。 此⼼本具 祖祖相傳 直下承擔 向上不墜 釋妙參\\u3000序於美國加州毗盧禪寺 推薦序003 序005 禪宗東⼟初祖⾄六祖之法脈傳承011 六祖壇經序020 ⾏由品第⼀：時⼤師⾄寶林039 ⾏由品第⼀：且聽惠能⾏由得法事意045 ⾏由品第⼀：⾃性若迷，福何可救055 ⾏由品第⼀：復兩⽇，有⼀童⼦於碓坊過069 般若品第⼆：次⽇，韋使君請益090 般若品第⼆：莫聞我說空便即著空098 般若品第⼆：若欲⼊甚深法界及般若三昧者111 般若品第⼆：若起正真般若觀照124 疑問品第三：⼀⽇韋刺史為師設⼤會齋134 疑問品第三：使君但⾏⼗善，何須更願往⽣144 疑問品第三：若欲修⾏，在家亦得155 定慧品第四：我此法⾨以定慧為本167 定慧品第四：⼀⾏三昧者178 定慧品第四：直⼼是道場189 坐禪品第五：此⾨坐禪，元不著⼼210 ' metadata={'source': 'data/V1_TheInterpretedChineseSutra.pdf', 'page': 1}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv() \n",
    "\n",
    "# Define a directory name\n",
    "model_name = os.getenv(\"MODEL_NAME_FOR_EMBEDDINGS\")\n",
    "directory_name = 'data' \n",
    "pdf_files = []\n",
    "\n",
    "pdf_files = [f for f in os.listdir(directory_name) if f.endswith('.pdf')]\n",
    "\n",
    "print(pdf_files)        \n",
    "\n",
    "docs = []\n",
    "\n",
    "for f in pdf_files:\n",
    "    pages = PyPDFLoader(directory_name + '/' + f).load()\n",
    "    docs.extend(pages)\n",
    "    \n",
    "    \n",
    "print(\"Total Number of Documents:\" + str(len(docs)))    \n",
    "\n",
    "print(docs[1])    \n",
    "\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=200,\n",
    "    chunk_overlap=100,\n",
    "    length_function=len\n",
    ")\n",
    "\n",
    "docs = text_splitter.split_documents(docs)\n",
    "\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "\n",
    "embeddings = OllamaEmbeddings(model=model_name)\n",
    "\n",
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "time_str = now.strftime(\"%Y-%m-%d_%H\")\n",
    "\n",
    "persist_directory = 'EmbeddingDBs/' + time_str + model_name\n",
    "\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "# Create the vector store\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents = docs,\n",
    "    embedding = embeddings,\n",
    "    persist_directory=persist_directory\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
